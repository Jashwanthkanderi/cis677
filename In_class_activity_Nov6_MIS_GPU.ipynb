{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN29Spg9w8fdafTMgJ1z/e0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trefftzc/cis677/blob/main/In_class_activity_Nov6_MIS_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaSnCGr2WZdo",
        "outputId": "8739d8ab-3932-4c55-eacc-5f3d81002397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing k4.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile k4.txt\n",
        "4\n",
        "0 1 1 1\n",
        "1 0 1 1\n",
        "1 1 0 1\n",
        "1 1 1 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile no_edges4.txt\n",
        "4\n",
        "0 0 0 0\n",
        "0 0 0 0\n",
        "0 0 0 0\n",
        "0 0 0 0\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx10D8zlF5QH",
        "outputId": "c0feb6ce-7558-4dbb-e99a-1c7eacef90dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing no_edges4.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile k16.txt\n",
        "16\n",
        "0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tEn4QJ2xtEi",
        "outputId": "2467ec5f-bbdf-498e-e20c-666d0c7a6f12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing k16.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile k20.txt\n",
        "20\n",
        "0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn5MFF5PE7LP",
        "outputId": "e5fabe36-5e95-4df8-8388-242cbd8647ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing k20.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile k24.txt\n",
        "24\n",
        "0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR-arjm4G2rP",
        "outputId": "226f795a-3079-4fdb-af81-5c98062082d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing k24.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_copy.py\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "from numba import cuda\n",
        "\n",
        "@cuda.jit\n",
        "def device_copy_matrix(src, dst):\n",
        "    x, y = cuda.grid(2)\n",
        "    if x < src.shape[0] and y < src.shape[1]:\n",
        "        dst[x, y] = src[x, y]\n",
        "\n",
        "\n",
        "\n",
        "def read_adjacency_matrix(file_name):\n",
        "  file_object = open(file_name, \"r\")\n",
        "  # Input the number of rows and columns\n",
        "  size = int(file_object.readline())\n",
        "  rows = size\n",
        "  cols = size\n",
        "  # Initialize an empty matrix\n",
        "  matrix = []\n",
        "\n",
        "  # Input the matrix elements\n",
        "  for i in range(rows):\n",
        "    row = list(map(int, file_object.readline().split()))\n",
        "    matrix.append(row)\n",
        "  # Display the matrix\n",
        "  # print(\"The matrix contained in the file \",file_name,\" is: \")\n",
        "  # for row in matrix:\n",
        "  #  print(row)\n",
        "  return matrix,size\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  adj_matrix,size = read_adjacency_matrix(sys.argv[1])\n",
        "  adj_matrix_numpy = np.array(adj_matrix)\n",
        "\n",
        "  arr1 = cuda.to_device(adj_matrix_numpy)\n",
        "  arr2 = cuda.device_array_like(arr1)\n",
        "\n",
        "  tpb = (size,size)\n",
        "  bpg = (ceil(arr1.shape[0]/tpb[0]), ceil(arr1.shape[1]/tpb[1]))\n",
        "  device_copy_matrix[bpg, tpb](arr1,arr2)\n",
        "\n",
        "  host_arr2 = arr2.copy_to_host()\n",
        "\n",
        "# Sanity check\n",
        "  np.testing.assert_equal(adj_matrix_numpy, host_arr2)\n",
        "  print(host_arr2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9JZQhQJWnv9",
        "outputId": "49df2e74-85b5-4d98-8867-1c2d2c53fe28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_copy.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python matrix_copy.py k4.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC9t_upMZN6v",
        "outputId": "554e3446-e371-48fa-e55f-1c0dbbe3e630"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "[[0 1 1 1]\n",
            " [1 0 1 1]\n",
            " [1 1 0 1]\n",
            " [1 1 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile max_ind_set_numba_cuda.py\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import numba\n",
        "from math import ceil\n",
        "from numba import cuda,types\n",
        "from numba.cuda.cudadrv.devicearray import DeviceNDArray\n",
        "import time\n",
        "\n",
        "# A reduction on the GPU\n",
        "@cuda.reduce\n",
        "def max_reduce(a, b):\n",
        "    if a < b:\n",
        "        return b\n",
        "    else:\n",
        "        return a\n",
        "\n",
        "@cuda.jit\n",
        "def device_copy_matrix(src, dst):\n",
        "    x, y = cuda.grid(2)\n",
        "    if x < src.shape[0] and y < src.shape[1]:\n",
        "        dst[x, y] = src[x, y]\n",
        "\n",
        "@cuda.jit\n",
        "def evaluateSubset(array_with_sizes:DeviceNDArray,adj_mat:DeviceNDArray,n:np.dtype=np.int64):\n",
        "   this_set=cuda.local.array(32,dtype=numba.types.int64)\n",
        "   value = cuda.grid(1)\n",
        "   sum0s = 0\n",
        "   sum1s = 0\n",
        "   mask = 1\n",
        "   n_elements_in_this_set = 0\n",
        "   for i in range(0,n):\n",
        "     if ((mask & value) != 0):\n",
        "       this_set[i] = 1\n",
        "       n_elements_in_this_set += 1\n",
        "     else:\n",
        "       this_set[i] = 0\n",
        "     mask = mask * 2\n",
        "   is_independent = True\n",
        "   for n1 in range(n):\n",
        "     for n2 in range(n):\n",
        "        if (this_set[n1]==1) and (this_set[n2]==1) and (adj_mat[n1][n2] == 1):\n",
        "          is_independent = False\n",
        "   if (is_independent):\n",
        "      array_with_sizes[value] = n_elements_in_this_set\n",
        "   else:\n",
        "      array_with_sizes[value] = 0\n",
        "\n",
        "\n",
        "\n",
        "def read_adjacency_matrix(file_name):\n",
        "  file_object = open(file_name, \"r\")\n",
        "  # Input the number of rows and columns\n",
        "  size = int(file_object.readline())\n",
        "  rows = size\n",
        "  cols = size\n",
        "  # Initialize an empty matrix\n",
        "  matrix = []\n",
        "\n",
        "  # Input the matrix elements\n",
        "  for i in range(rows):\n",
        "    row = list(map(int, file_object.readline().split()))\n",
        "    matrix.append(row)\n",
        "  # Display the matrix\n",
        "  # print(\"The matrix contained in the file \",file_name,\" is: \")\n",
        "  # for row in matrix:\n",
        "  #  print(row)\n",
        "  return matrix,size\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  file_name = sys.argv[1]\n",
        "  adj_matrix,size = read_adjacency_matrix(file_name)\n",
        "  adj_matrix_numpy = np.array(adj_matrix)\n",
        "\n",
        "  arr1 = cuda.to_device(adj_matrix_numpy)\n",
        "  adj_matrix_device = cuda.device_array_like(arr1)\n",
        "\n",
        "  tpb = (size,size)\n",
        "  bpg = (ceil(arr1.shape[0]/tpb[0]), ceil(arr1.shape[1]/tpb[1]))\n",
        "  device_copy_matrix[bpg, tpb](arr1,adj_matrix_device)\n",
        "\n",
        "\n",
        "\n",
        "  sizePowerSet = 2 ** size\n",
        "  sizesGPU = cuda.device_array(sizePowerSet, dtype=np.int32)\n",
        "  start_time = time.time()\n",
        "  evaluateSubset.forall(sizePowerSet)( sizesGPU,adj_matrix_device,size)\n",
        "  cuda.synchronize()\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(file_name,\" = Time for evaluation including compilation: \",elapsed_time,\" seconds.\")\n",
        "\n",
        "  # Perform a reduction to find the maximum value\n",
        "  solution = max_reduce(sizesGPU,init=0)\n",
        "\n",
        "  start_time = time.time()\n",
        "  evaluateSubset.forall(sizePowerSet)( sizesGPU,adj_matrix_device,size)\n",
        "  cuda.synchronize()\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(file_name,\" - Time for evaluation excluding compilation: \",elapsed_time,\" seconds.\")\n",
        "\n",
        "  # Perform a reduction on the GPU to find the maximum value\n",
        "  start_time = time.time()\n",
        "  solution = max_reduce(sizesGPU,init=0)\n",
        "  cuda.synchronize()\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(file_name,\" - Time for reduction on GPU: \",elapsed_time,\" seconds. \",sizePowerSet,\" elements.\")\n",
        "  # Consider the alternative of copying back the array with the results from the GPU\n",
        "  # and performing the reduction on the CPU\n",
        "  start_time = time.time()\n",
        "  sizesCPU = np.zeros(sizePowerSet,dtype=np.int32)\n",
        "  sizesGPU.copy_to_host(sizesCPU)\n",
        "  cuda.synchronize()\n",
        "  solution = np.max(sizesCPU)\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(file_name,\" - Time for reduction on CPU (including copy): \",elapsed_time,\" seconds. \",sizePowerSet,\" elements.\")\n",
        "  print(file_name,\" - The size of a maximum independent set is: \",solution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o60hCJQDjmDq",
        "outputId": "5886f3c8-638b-47cc-db79-34483f51bd3c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting max_ind_set_numba_cuda.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python max_ind_set_numba_cuda.py no_edges4.txt\n",
        "!python max_ind_set_numba_cuda.py k4.txt\n",
        "!python max_ind_set_numba_cuda.py k16.txt\n",
        "!python max_ind_set_numba_cuda.py k20.txt\n",
        "!python max_ind_set_numba_cuda.py k24.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_JdzxrB91S-",
        "outputId": "5dec9a92-dfe4-4562-f294-415bd069942b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "no_edges4.txt  = Time for evaluation including compilation:  0.1748654842376709  seconds.\n",
            "no_edges4.txt  - Time for evaluation excluding compilation:  0.0005457401275634766  seconds.\n",
            "no_edges4.txt  - Time for reduction on GPU:  0.0006816387176513672  seconds.  16  elements.\n",
            "no_edges4.txt  - Time for reduction on CPU (including copy):  0.00019812583923339844  seconds.  16  elements.\n",
            "no_edges4.txt  - The size of a maximum independent set is:  4\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "k4.txt  = Time for evaluation including compilation:  0.17244410514831543  seconds.\n",
            "k4.txt  - Time for evaluation excluding compilation:  0.0004458427429199219  seconds.\n",
            "k4.txt  - Time for reduction on GPU:  0.0005905628204345703  seconds.  16  elements.\n",
            "k4.txt  - Time for reduction on CPU (including copy):  0.0001888275146484375  seconds.  16  elements.\n",
            "k4.txt  - The size of a maximum independent set is:  1\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 64 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "k16.txt  = Time for evaluation including compilation:  0.18710589408874512  seconds.\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "k16.txt  - Time for evaluation excluding compilation:  0.009380578994750977  seconds.\n",
            "k16.txt  - Time for reduction on GPU:  0.0006740093231201172  seconds.  65536  elements.\n",
            "k16.txt  - Time for reduction on CPU (including copy):  0.0003631114959716797  seconds.  65536  elements.\n",
            "k16.txt  - The size of a maximum independent set is:  1\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "k20.txt  = Time for evaluation including compilation:  0.35183119773864746  seconds.\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 64 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "k20.txt  - Time for evaluation excluding compilation:  0.1205434799194336  seconds.\n",
            "k20.txt  - Time for reduction on GPU:  0.0009224414825439453  seconds.  1048576  elements.\n",
            "k20.txt  - Time for reduction on CPU (including copy):  0.003763437271118164  seconds.  1048576  elements.\n",
            "k20.txt  - The size of a maximum independent set is:  1\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "k24.txt  = Time for evaluation including compilation:  3.2797024250030518  seconds.\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 64 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "k24.txt  - Time for evaluation excluding compilation:  3.0021743774414062  seconds.\n",
            "k24.txt  - Time for reduction on GPU:  0.0010728836059570312  seconds.  16777216  elements.\n",
            "k24.txt  - Time for reduction on CPU (including copy):  0.05544924736022949  seconds.  16777216  elements.\n",
            "k24.txt  - The size of a maximum independent set is:  1\n"
          ]
        }
      ]
    }
  ]
}