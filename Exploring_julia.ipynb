{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia 1.7.2",
      "name": "julia-1.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trefftzc/cis677/blob/main/Exploring_julia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMGwZ7aFJL8Y"
      },
      "source": [
        "# Installation cell\n",
        "%%capture\n",
        "%%shell\n",
        "if ! command -v julia 3>&1 > /dev/null\n",
        "then\n",
        "    wget -q 'https://julialang-s3.julialang.org/bin/linux/x64/1.7/julia-1.7.2-linux-x86_64.tar.gz' \\\n",
        "        -O /tmp/julia.tar.gz\n",
        "    tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "    rm /tmp/julia.tar.gz\n",
        "fi\n",
        "julia -e 'using Pkg; pkg\"add IJulia; precompile;\"'\n",
        "echo 'Done'\n",
        "export JULIA_NUM_THREADS=2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdMpcQduyaQc"
      },
      "source": [
        "After you run the first cell (the the cell directly above this text), go to Colab's menu bar and select **Edit** and select **Notebook settings** from the drop down. Select *Julia 1.7* in Runtime type. You can also select your prefered harwdware acceleration (defaults to GPU).\n",
        "\n",
        "<br/>You should see something like this:\n",
        "\n",
        "> ![Colab Img](https://raw.githubusercontent.com/Dsantra92/Julia-on-Colab/master/misc/julia_menu.png)\n",
        "\n",
        "<br/>Click on SAVE\n",
        "<br/>**We are ready to get going**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIxu4TjlJnBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719c09ca-934d-4d8d-cbf2-1213e09b7dff"
      },
      "source": [
        "VERSION"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "v\"1.7.2\""
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following piece of code was written by Dr. William Godoy from ORNL.\n",
        "The complete code is available in his github repository: https://github.com/williamfgc/simple-gemm\n",
        "\n",
        "This initial version is a sequential version of matrix multiplication\n"
      ],
      "metadata": {
        "id": "9AD49P5OvGgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import Random\n",
        "\n",
        "@doc \"\"\"\n",
        "Simplified gemm: C = alpha A x B + C where alpha = 1 , C = zeros,\n",
        "so:\n",
        "C = A x B\n",
        "\"\"\"\n",
        "function gemm!(A::Array{Float32,2}, B::Array{Float32,2}, C::Array{Float32,2})\n",
        "\n",
        "    A_rows = size(A)[1]\n",
        "    A_cols = size(A)[2]\n",
        "    B_cols = size(B)[2]\n",
        "\n",
        "     for j = 1:B_cols\n",
        "        for l = 1:A_cols\n",
        "            @inbounds temp::Float32 = B[l, j]::Float32\n",
        "            for i = 1:A_rows\n",
        "                @inbounds C[i, j] += temp * A[i, l]\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "end\n",
        "\n",
        "function main(args::Array{String,1})::Int32\n",
        "\n",
        "    # must initialize scalars\n",
        "    A_rows::Int64 = -1\n",
        "    A_cols::Int64 = -1\n",
        "    B_rows::Int64 = -1\n",
        "    B_cols::Int64 = -1\n",
        "\n",
        "    steps::Int32 = 1\n",
        "\n",
        "    @show args\n",
        "\n",
        "    # args don't include Julia executable and program\n",
        "    nargs = size(args)[1]\n",
        "\n",
        "    if nargs == 4 || nargs == 3\n",
        "        A_rows = parse(Int64, args[1])\n",
        "        A_cols = parse(Int64, args[2])\n",
        "        B_rows = parse(Int64, args[2])\n",
        "        B_cols = parse(Int64, args[3])\n",
        "\n",
        "        if nargs == 4\n",
        "            steps = parse(Int32, args[4])\n",
        "        end\n",
        "    else\n",
        "        throw(\n",
        "            ArgumentError( \"Usage: \\n - 3 arguments: matrix A rows, matrix A cols and matrix B cols\\n- 4 arguments: matrix A rows, matrix A cols and matrix B cols, steps\",\n",
        "            ),\n",
        "        )\n",
        "    end\n",
        "\n",
        "    # Julia is column-based (like Fortran)\n",
        "    @time begin\n",
        "\n",
        "        print(\"Time to allocate A \")\n",
        "        @time A = Array{Float32,2}(undef, A_rows, A_cols)\n",
        "        print(\"Time to allocate B \")\n",
        "        @time B = Array{Float32,2}(undef, B_rows, B_cols)\n",
        "        print(\"Time to initialize C \")\n",
        "        @time C = zeros(Float32, A_rows, B_cols)\n",
        "\n",
        "        print(\"Time to fill A \")\n",
        "        @time Random.rand!(A)\n",
        "        print(\"Time to fill B \")\n",
        "        @time Random.rand!(B)\n",
        "\n",
        "        print(\"Time to simple gemm \")\n",
        "        @time gemm!(A, B, C)\n",
        "\n",
        "        if steps > 1\n",
        "            timings = zeros(steps)\n",
        "            for i = 2:steps\n",
        "                print(\"Time to simple gemm \")\n",
        "                 timings[i] = @elapsed gemm!(A, B, C)\n",
        "                println(timings[i])\n",
        "            end\n",
        "\n",
        "            average_time = sum(timings) / (steps - 1)\n",
        "            gflops = (2 * A_rows * A_cols * B_cols) * 1E-9 / average_time\n",
        "            println(\n",
        "                \"GFLOPS: \",\n",
        "                gflops,\n",
        "                \" steps: \",\n",
        "                steps,\n",
        "                \" average_time: \",\n",
        "                average_time,\n",
        "            )\n",
        "        end\n",
        "\n",
        "        print(\"Time to total time \")\n",
        "    end\n",
        "    return 0\n",
        "\n",
        "end\n",
        "\n",
        "\n",
        "\n",
        "main([\"500\",\"500\",\"500\",\"5\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIDSChcou0w9",
        "outputId": "f3020577-c7b2-4a0f-8909-3bb656436b56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "args = [\"500\", \"500\", \"500\", \"5\"]\n",
            "Time to allocate A   0.000004 seconds (2 allocations: 976.609 KiB)\n",
            "Time to allocate B   0.000019 seconds (2 allocations: 976.609 KiB)\n",
            "Time to initialize C   0.000660 seconds (2 allocations: 976.609 KiB)\n",
            "Time to fill A   0.000147 seconds\n",
            "Time to fill B   0.000715 seconds\n",
            "Time to simple gemm   0.026087 seconds\n",
            "Time to simple gemm 0.025073825\n",
            "Time to simple gemm 0.026045731\n",
            "Time to simple gemm 0.024597237\n",
            "Time to simple gemm 0.025052874\n",
            "GFLOPS: 9.923621162705638 steps: 5 average_time: 0.025192416750000002\n",
            "Time to total time   0.329998 seconds (116.96 k allocations: 9.448 MiB, 4.82% gc time, 60.71% compilation time)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This second version uses Thread parallelization.\n",
        "Something similar to using OpenMP parallel loop or NUMBA's prange"
      ],
      "metadata": {
        "id": "kkDXmoTTx6tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Threads.nthreads()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N_GnTA7zE30",
        "outputId": "60bb624c-9ea1-432b-e80b-0843d9acd1fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import Random\n",
        "\n",
        "@doc \"\"\"\n",
        "Simplified gemm: C = alpha A x B + C where alpha = 1 , C = zeros,\n",
        "so:\n",
        "C = A x B\n",
        "\"\"\"\n",
        "function gemm!(A::Array{Float32,2}, B::Array{Float32,2}, C::Array{Float32,2})\n",
        "\n",
        "    A_rows = size(A)[1]\n",
        "    A_cols = size(A)[2]\n",
        "    B_cols = size(B)[2]\n",
        "\n",
        "    Threads.@threads for j = 1:B_cols\n",
        "        for l = 1:A_cols\n",
        "            @inbounds temp::Float32 = B[l, j]::Float32\n",
        "            for i = 1:A_rows\n",
        "                @inbounds C[i, j] += temp * A[i, l]\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "end\n",
        "\n",
        "function main(args::Array{String,1})::Int32\n",
        "\n",
        "    # must initialize scalars\n",
        "    A_rows::Int64 = -1\n",
        "    A_cols::Int64 = -1\n",
        "    B_rows::Int64 = -1\n",
        "    B_cols::Int64 = -1\n",
        "\n",
        "    steps::Int32 = 1\n",
        "\n",
        "    @show args\n",
        "\n",
        "    # args don't include Julia executable and program\n",
        "    nargs = size(args)[1]\n",
        "\n",
        "    if nargs == 4 || nargs == 3\n",
        "        A_rows = parse(Int64, args[1])\n",
        "        A_cols = parse(Int64, args[2])\n",
        "        B_rows = parse(Int64, args[2])\n",
        "        B_cols = parse(Int64, args[3])\n",
        "\n",
        "        if nargs == 4\n",
        "            steps = parse(Int32, args[4])\n",
        "        end\n",
        "    else\n",
        "        throw(\n",
        "            ArgumentError( \"Usage: \\n - 3 arguments: matrix A rows, matrix A cols and matrix B cols\\n- 4 arguments: matrix A rows, matrix A cols and matrix B cols, steps\",\n",
        "            ),\n",
        "        )\n",
        "    end\n",
        "\n",
        "    # Julia is column-based (like Fortran)\n",
        "    @time begin\n",
        "\n",
        "        print(\"Time to allocate A \")\n",
        "        @time A = Array{Float32,2}(undef, A_rows, A_cols)\n",
        "        print(\"Time to allocate B \")\n",
        "        @time B = Array{Float32,2}(undef, B_rows, B_cols)\n",
        "        print(\"Time to initialize C \")\n",
        "        @time C = zeros(Float32, A_rows, B_cols)\n",
        "\n",
        "        print(\"Time to fill A \")\n",
        "        @time Random.rand!(A)\n",
        "        print(\"Time to fill B \")\n",
        "        @time Random.rand!(B)\n",
        "\n",
        "        print(\"Time to simple gemm \")\n",
        "        @time gemm!(A, B, C)\n",
        "\n",
        "        if steps > 1\n",
        "            timings = zeros(steps)\n",
        "            for i = 2:steps\n",
        "                print(\"Time to simple gemm \")\n",
        "                 timings[i] = @elapsed gemm!(A, B, C)\n",
        "                println(timings[i])\n",
        "            end\n",
        "\n",
        "            average_time = sum(timings) / (steps - 1)\n",
        "            gflops = (2 * A_rows * A_cols * B_cols) * 1E-9 / average_time\n",
        "            println(\n",
        "                \"GFLOPS: \",\n",
        "                gflops,\n",
        "                \" steps: \",\n",
        "                steps,\n",
        "                \" average_time: \",\n",
        "                average_time,\n",
        "            )\n",
        "        end\n",
        "\n",
        "        print(\"Time to total time \")\n",
        "    end\n",
        "    return 0\n",
        "\n",
        "end\n",
        "\n",
        "\n",
        "\n",
        "main([\"500\",\"500\",\"500\",\"5\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ5cnHS6x47E",
        "outputId": "a5dbb4d3-5b96-4796-cd21-ff3522aa9f00"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "args = [\"500\", \"500\", \"500\", \"5\"]\n",
            "Time to allocate A   0.000023 seconds (2 allocations: 976.609 KiB)\n",
            "Time to allocate B   0.000006 seconds (2 allocations: 976.609 KiB)\n",
            "Time to initialize C   0.000488 seconds (2 allocations: 976.609 KiB)\n",
            "Time to fill A   0.000406 seconds\n",
            "Time to fill B   0.000527 seconds\n",
            "Time to simple gemm   0.077795 seconds (63.66 k allocations: 3.463 MiB, 78.08% compilation time)\n",
            "Time to simple gemm 0.017281473\n",
            "Time to simple gemm 0.016447019\n",
            "Time to simple gemm 0.017067844\n",
            "Time to simple gemm 0.016816876\n",
            "GFLOPS: 14.790008792956026 steps: 5 average_time: 0.016903303\n",
            "Time to total time   0.147348 seconds (64.23 k allocations: 6.348 MiB, 41.22% compilation time)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR7Ox6Ax0ypi"
      },
      "source": [
        "**The next three cells are for GPU benchmarking. If you are using this notebook for the first time and have GPU enabled, you can give it a try.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y5TUI-Ll4cY"
      },
      "source": [
        "### Optional GPU Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHKANz2J0GDW",
        "outputId": "a4c00951-fdc4-4dbe-bb4b-df51601bd46a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "using Pkg\n",
        "Pkg.add([\"BenchmarkTools\", \"CUDA\"])\n",
        "using BenchmarkTools, CUDA\n",
        "\n",
        "if has_cuda_gpu()\n",
        "  print(\"The GPU device is:\", CUDA.device())\n",
        "end"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The GPU device is:CuDevice(0)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GPUArraysCore ────────── v0.1.5\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m IrrationalConstants ──── v0.2.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CUDA_Driver_jll ──────── v0.5.0+1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Adapt ────────────────── v3.7.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Scratch ──────────────── v1.2.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BenchmarkTools ───────── v1.5.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SpecialFunctions ─────── v2.3.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CUDA_Runtime_Discovery ─ v0.2.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m TimerOutputs ─────────── v0.5.23\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StaticArraysCore ─────── v1.4.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m AbstractFFTs ─────────── v1.5.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GPUCompiler ──────────── v0.21.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LLVMExtra_jll ────────── v0.0.23+0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m UnsafeAtomicsLLVM ────── v0.1.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StaticArrays ─────────── v1.9.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CEnum ────────────────── v0.4.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CUDA_Runtime_jll ─────── v0.6.0+0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BFloat16s ────────────── v0.4.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Reexport ─────────────── v1.2.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Random123 ────────────── v1.6.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChainRulesCore ───────── v1.23.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GPUArrays ────────────── v8.8.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m RandomNumbers ────────── v1.5.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ExprTools ────────────── v0.1.10\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LogExpFunctions ──────── v0.3.27\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Requires ─────────────── v1.3.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MacroTools ───────────── v0.5.13\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m KernelAbstractions ───── v0.9.18\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OpenSpecFun_jll ──────── v0.5.5+0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Compat ───────────────── v4.14.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m UnsafeAtomics ────────── v0.2.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m InverseFunctions ─────── v0.1.13\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChangesOfVariables ───── v0.1.8\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Atomix ───────────────── v0.1.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DocStringExtensions ──── v0.9.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LLVM ─────────────────── v6.1.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CUDA ─────────────────── v4.4.2\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.7/Project.toml`\n",
            " \u001b[90m [6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.5.0\u001b[39m\n",
            " \u001b[90m [052768ef] \u001b[39m\u001b[92m+ CUDA v4.4.2\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.7/Manifest.toml`\n",
            " \u001b[90m [621f4979] \u001b[39m\u001b[92m+ AbstractFFTs v1.5.0\u001b[39m\n",
            " \u001b[90m [79e6a3ab] \u001b[39m\u001b[92m+ Adapt v3.7.2\u001b[39m\n",
            " \u001b[90m [a9b6321e] \u001b[39m\u001b[92m+ Atomix v0.1.0\u001b[39m\n",
            " \u001b[90m [ab4f0b2a] \u001b[39m\u001b[92m+ BFloat16s v0.4.2\u001b[39m\n",
            " \u001b[90m [6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.5.0\u001b[39m\n",
            " \u001b[90m [fa961155] \u001b[39m\u001b[92m+ CEnum v0.4.2\u001b[39m\n",
            " \u001b[90m [052768ef] \u001b[39m\u001b[92m+ CUDA v4.4.2\u001b[39m\n",
            " \u001b[90m [1af6417a] \u001b[39m\u001b[92m+ CUDA_Runtime_Discovery v0.2.4\u001b[39m\n",
            " \u001b[90m [d360d2e6] \u001b[39m\u001b[92m+ ChainRulesCore v1.23.0\u001b[39m\n",
            " \u001b[90m [9e997f8a] \u001b[39m\u001b[92m+ ChangesOfVariables v0.1.8\u001b[39m\n",
            " \u001b[90m [34da2185] \u001b[39m\u001b[92m+ Compat v4.14.0\u001b[39m\n",
            " \u001b[90m [ffbed154] \u001b[39m\u001b[92m+ DocStringExtensions v0.9.3\u001b[39m\n",
            " \u001b[90m [e2ba6199] \u001b[39m\u001b[92m+ ExprTools v0.1.10\u001b[39m\n",
            " \u001b[90m [0c68f7d7] \u001b[39m\u001b[92m+ GPUArrays v8.8.1\u001b[39m\n",
            " \u001b[90m [46192b85] \u001b[39m\u001b[92m+ GPUArraysCore v0.1.5\u001b[39m\n",
            " \u001b[90m [61eb1bfa] \u001b[39m\u001b[92m+ GPUCompiler v0.21.4\u001b[39m\n",
            " \u001b[90m [3587e190] \u001b[39m\u001b[92m+ InverseFunctions v0.1.13\u001b[39m\n",
            " \u001b[90m [92d709cd] \u001b[39m\u001b[92m+ IrrationalConstants v0.2.2\u001b[39m\n",
            " \u001b[90m [63c18a36] \u001b[39m\u001b[92m+ KernelAbstractions v0.9.18\u001b[39m\n",
            " \u001b[90m [929cbde3] \u001b[39m\u001b[92m+ LLVM v6.1.0\u001b[39m\n",
            " \u001b[90m [2ab3a3ac] \u001b[39m\u001b[92m+ LogExpFunctions v0.3.27\u001b[39m\n",
            " \u001b[90m [1914dd2f] \u001b[39m\u001b[92m+ MacroTools v0.5.13\u001b[39m\n",
            " \u001b[90m [74087812] \u001b[39m\u001b[92m+ Random123 v1.6.2\u001b[39m\n",
            " \u001b[90m [e6cf234a] \u001b[39m\u001b[92m+ RandomNumbers v1.5.3\u001b[39m\n",
            " \u001b[90m [189a3867] \u001b[39m\u001b[92m+ Reexport v1.2.2\u001b[39m\n",
            " \u001b[90m [ae029012] \u001b[39m\u001b[92m+ Requires v1.3.0\u001b[39m\n",
            " \u001b[90m [6c6a2e73] \u001b[39m\u001b[92m+ Scratch v1.2.1\u001b[39m\n",
            " \u001b[90m [276daf66] \u001b[39m\u001b[92m+ SpecialFunctions v2.3.1\u001b[39m\n",
            " \u001b[90m [90137ffa] \u001b[39m\u001b[92m+ StaticArrays v1.9.3\u001b[39m\n",
            " \u001b[90m [1e83bf80] \u001b[39m\u001b[92m+ StaticArraysCore v1.4.2\u001b[39m\n",
            " \u001b[90m [a759f4b9] \u001b[39m\u001b[92m+ TimerOutputs v0.5.23\u001b[39m\n",
            " \u001b[90m [013be700] \u001b[39m\u001b[92m+ UnsafeAtomics v0.2.1\u001b[39m\n",
            " \u001b[90m [d80eeb9a] \u001b[39m\u001b[92m+ UnsafeAtomicsLLVM v0.1.3\u001b[39m\n",
            " \u001b[90m [4ee394cb] \u001b[39m\u001b[92m+ CUDA_Driver_jll v0.5.0+1\u001b[39m\n",
            " Downloading artifact: CUDA_Driver\n",
            "\u001b[31m→\u001b[39m\u001b[90m [76a88914] \u001b[39m\u001b[92m+ CUDA_Runtime_jll v0.6.0+0\u001b[39m\n",
            " \u001b[90m [dad2f222] \u001b[39m\u001b[92m+ LLVMExtra_jll v0.0.23+0\u001b[39m\n",
            " \u001b[90m [efe28fd5] \u001b[39m\u001b[92m+ OpenSpecFun_jll v0.5.5+0\u001b[39m\n",
            " \u001b[90m [4af54fe1] \u001b[39m\u001b[92m+ LazyArtifacts\u001b[39m\n",
            " \u001b[90m [37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra\u001b[39m\n",
            " \u001b[90m [9abbd945] \u001b[39m\u001b[92m+ Profile\u001b[39m\n",
            " \u001b[90m [2f01184e] \u001b[39m\u001b[92m+ SparseArrays\u001b[39m\n",
            " \u001b[90m [10745b16] \u001b[39m\u001b[92m+ Statistics\u001b[39m\n",
            " \u001b[90m [e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll\u001b[39m\n",
            " \u001b[90m [4536629a] \u001b[39m\u001b[92m+ OpenBLAS_jll\u001b[39m\n",
            " \u001b[90m [05823500] \u001b[39m\u001b[92m+ OpenLibm_jll\u001b[39m\n",
            " \u001b[90m [8e850b90] \u001b[39m\u001b[92m+ libblastrampoline_jll\u001b[39m\n",
            "\u001b[32m\u001b[1m        Info\u001b[22m\u001b[39m packages marked with \u001b[31m→\u001b[39m not downloaded, use `instantiate` to download\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mOpenLibm_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mRequires\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mCompat\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mInverseFunctions\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mReexport\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mExprTools\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mDocStringExtensions\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mCompilerSupportLibraries_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mIrrationalConstants\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mBFloat16s\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mScratch\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mCEnum\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mUnsafeAtomics\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArraysCore\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mCUDA_Runtime_Discovery\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mMacroTools\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mLLVMExtra_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mCUDA_Runtime_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39mBenchmarkTools\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mAdapt\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mChangesOfVariables\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mRandomNumbers\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mOpenBLAS_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mChainRulesCore\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mAtomix\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mTimerOutputs\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mOpenSpecFun_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mGPUArraysCore\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mRandom123\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mlibblastrampoline_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mAbstractFFTs\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mLLVM\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mLogExpFunctions\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mUnsafeAtomicsLLVM\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mGPUArrays\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrays\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mSpecialFunctions\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mGPUCompiler\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mKernelAbstractions\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39mCUDA\n",
            "  40 dependencies successfully precompiled in 81 seconds (17 already precompiled)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7Mbcm00lnxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d60c0ff8-e3ae-4681-b93d-940b6298a2d8"
      },
      "source": [
        "mcpu = rand(2^10, 2^10)\n",
        "@benchmark mcpu*mcpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 126 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m35.569 ms\u001b[22m\u001b[39m … \u001b[35m74.292 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m38.148 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m39.703 ms\u001b[22m\u001b[39m ± \u001b[32m 5.308 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.80% ± 2.28%\n",
              "\n",
              "  \u001b[39m▁\u001b[39m▅\u001b[39m \u001b[39m▁\u001b[39m▆\u001b[39m▄\u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m▃\u001b[39m▆\u001b[32m▃\u001b[39m\u001b[39m▆\u001b[39m▃\u001b[39m▆\u001b[39m▅\u001b[39m▇\u001b[39m▁\u001b[39m▅\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m \u001b[39m▃\n",
              "  35.6 ms\u001b[90m         Histogram: frequency by time\u001b[39m        60.3 ms \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m8.00 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m2\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMHRbF5J-vmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e1e175-3e00-4eaf-d817-e28c8c8c3afb"
      },
      "source": [
        "println(\"The CuArrray operation should be much faster (~100 times) than the CPU implemenation.\")\n",
        "mgpu = cu(mcpu)\n",
        "@benchmark CUDA.@sync mgpu*mgpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The CuArrray operation should be much faster (~100 times) than the CPU implemenation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 7610 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m469.377 μs\u001b[22m\u001b[39m … \u001b[35m 19.478 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 48.84%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m632.475 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m647.089 μs\u001b[22m\u001b[39m ± \u001b[32m335.904 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.37% ±  0.77%\n",
              "\n",
              "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▆\u001b[32m▄\u001b[39m\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m▇\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m▃\n",
              "  469 μs\u001b[90m           Histogram: frequency by time\u001b[39m          906 μs \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m912 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m41\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = 10\n",
        "b = 20\n",
        "c = a + b"
      ],
      "metadata": {
        "id": "OVr67QFojFhW",
        "outputId": "c7d0e981-1cd7-4a38-f4da-98b6f9c9b43d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function add(a,b)\n",
        "  return a+b\n",
        "end"
      ],
      "metadata": {
        "id": "-W0Q8adAj23X",
        "outputId": "14a96ec4-2dda-4254-a75e-9e5ba76a55ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "add (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = add(a,b)"
      ],
      "metadata": {
        "id": "fT2pBj52j9C2",
        "outputId": "4215da40-9796-433f-bf67-052ff8fc3df5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = 3.1416\n",
        "y = 1.4142\n",
        "z = add(x,y)"
      ],
      "metadata": {
        "id": "5XqaKA8bkA1G",
        "outputId": "77f7b026-7acd-482f-96aa-39e2829da147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.5558"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}